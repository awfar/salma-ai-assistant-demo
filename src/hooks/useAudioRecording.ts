
import { useState, useRef, useCallback } from "react";
import { createVoiceRecorder, VoiceRecorderInterface } from "@/utils/voiceRecorder";
import { useToast } from "@/hooks/use-toast";
import { speechTranscriptionService } from "@/services/speechTranscriptionService";

interface UseAudioRecordingProps {
  onTranscriptReady: (text: string) => Promise<void>;
  onTranscriptChange: (text: string) => void;
}

interface UseAudioRecordingReturn {
  isRecording: boolean;
  audioLevel: number;
  startRecording: () => Promise<void>;
  stopRecording: (noSpeechDetected?: boolean) => Promise<void>;
  recorderRef: React.MutableRefObject<VoiceRecorderInterface | null>;
}

export const useAudioRecording = ({
  onTranscriptReady,
  onTranscriptChange
}: UseAudioRecordingProps): UseAudioRecordingReturn => {
  const [isRecording, setIsRecording] = useState<boolean>(false);
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const { toast } = useToast();
  
  // References
  const recorderRef = useRef<VoiceRecorderInterface | null>(null);
  const noSpeechTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  
  // Show error message helper
  const showError = useCallback((message: string, duration: number = 3000) => {
    toast({
      title: "Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª",
      description: message,
      variant: "destructive",
    });
  }, [toast]);

  // Handle start of recording
  const startRecording = useCallback(async () => {
    try {
      // Hide any error messages
      
      // Start recording
      if (!recorderRef.current) {
        recorderRef.current = createVoiceRecorder({
          onAudioLevel: (level) => {
            setAudioLevel(level);
          }
        });
      }
      
      console.log("ğŸ¤ Ø¨Ø¯Ø¡ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª...");
      await recorderRef.current.startRecording();
      setIsRecording(true);
      onTranscriptChange("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹...");
      
      // Set a timeout to check if no speech is detected
      noSpeechTimeoutRef.current = setTimeout(() => {
        if (audioLevel < 0.1 && isRecording) {
          console.log("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ÙƒÙ„Ø§Ù… Ø®Ù„Ø§Ù„ ÙØªØ±Ø© Ø§Ù„Ù…Ù‡Ù„Ø©");
          stopRecording(true);
        }
      }, 6500); // Check just before 7 second max recording time

    } catch (err) {
      console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„:", err);
      setIsRecording(false);
      showError("Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ÙˆØµÙˆÙ„.", 3000);
    }
  }, [audioLevel, isRecording, onTranscriptChange, showError]);
  
  // Handle end of recording
  const stopRecording = useCallback(async (noSpeechDetected = false) => {
    try {
      if (!recorderRef.current || !recorderRef.current.isRecording()) {
        setIsRecording(false);
        return;
      }
      
      // Clear no speech timeout
      if (noSpeechTimeoutRef.current) {
        clearTimeout(noSpeechTimeoutRef.current);
        noSpeechTimeoutRef.current = null;
      }
      
      setIsRecording(false);
      onTranscriptChange("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª...");
      
      // Stop the recording and get the audio blob
      console.log("ğŸ¤ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ÙˆØ§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ...");
      const audioBlob = await recorderRef.current.stopRecording();
      
      // If we detected no speech, show a message
      if (noSpeechDetected || audioBlob.size < 1000) {
        console.warn("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ÙƒÙ„Ø§Ù… Ø£Ùˆ Ø§Ù„ØµÙˆØª ØµØºÙŠØ± Ø¬Ø¯Ù‹Ø§:", audioBlob.size);
        showError("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØªØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰", 2000);
        return;
      }
      
      console.log(`ğŸ¤ ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ: ${audioBlob.size} Ø¨Ø§ÙŠØªØŒ Ù†ÙˆØ¹: ${audioBlob.type}`);
      
      // Transcribe the audio
      try {
        console.log("ğŸ”„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ...");
        const text = await speechTranscriptionService.transcribeAudio(audioBlob);
        
        if (!text) {
          console.error("âŒ Ù„Ù… ÙŠØªÙ… Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙŠ Ù†Øµ Ù…Ù† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„");
          throw new Error("ÙØ´Ù„ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù… Ø¥Ù„Ù‰ Ù†Øµ");
        }
        
        console.log("âœ… Ù†Ø¬Ø­Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­ÙˆÙŠÙ„:", text);
        
        // Process the transcribed text
        await onTranscriptReady(text);
      } catch (transcriptionError) {
        console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­ÙˆÙŠÙ„:", transcriptionError);
        showError(
          transcriptionError instanceof Error 
            ? transcriptionError.message 
            : "Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.", 
          3000
        );
      }
      
    } catch (err) {
      console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„:", err);
      setIsRecording(false);
      onTranscriptChange("");
      
      showError("Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØªØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.", 3000);
    }
  }, [onTranscriptChange, onTranscriptReady, showError]);

  return {
    isRecording,
    audioLevel,
    startRecording,
    stopRecording,
    recorderRef
  };
};
