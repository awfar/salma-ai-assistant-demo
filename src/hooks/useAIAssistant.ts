
import { useState, useCallback, useRef, useEffect } from "react";
import { useToast } from "./use-toast";
import { supabase } from "@/integrations/supabase/client";

interface TextToSpeechCallbacks {
  onStart?: () => void;
  onEnd?: () => void;
  onChunk?: (chunk: ArrayBuffer) => void;
  onStreamStart?: (mediaSource: MediaSource | AudioBufferSourceNode) => void;
}

interface UseAIAssistantReturn {
  askAssistant: (question: string) => Promise<string | null>;
  textToSpeech: (text: string, callbacks?: TextToSpeechCallbacks) => Promise<string | null>;
  streamToSpeech: (text: string, callbacks?: TextToSpeechCallbacks) => Promise<void>;
  isLoading: boolean;
  isAudioLoading: boolean;
  cancelRequest?: () => void;
}

export const useAIAssistant = (): UseAIAssistantReturn => {
  const [isLoading, setIsLoading] = useState(false);
  const [isAudioLoading, setIsAudioLoading] = useState(false);
  const { toast } = useToast();
  const abortControllerRef = useRef<AbortController | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  
  // ØªÙ‡ÙŠØ¦Ø© AudioContext
  useEffect(() => {
    // ØªØ£Ø¬ÙŠÙ„ Ø¥Ù†Ø´Ø§Ø¡ AudioContext Ø­ØªÙ‰ ÙŠÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ ØªÙØ§Ø¹Ù„ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
    const initAudioContext = () => {
      try {
        if (!audioContextRef.current) {
          const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
          audioContextRef.current = new AudioContextClass();
          console.log("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ AudioContext Ø¨Ù†Ø¬Ø§Ø­");
        }
      } catch (err) {
        console.error("âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ AudioContext:", err);
      }
    };

    // Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø£Ø­Ø¯Ø§Ø« Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    const handleUserInteraction = () => {
      initAudioContext();
      
      // Ø¥Ø°Ø§ ÙƒØ§Ù† AudioContext Ù…ØªÙˆÙ‚ÙÙ‹Ø§ØŒ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„Ù‡
      if (audioContextRef.current && audioContextRef.current.state === "suspended") {
        audioContextRef.current.resume();
      }
    };

    // Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ù„Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø§Ù„ØªÙŠ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ ØªÙØ§Ø¹Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    window.addEventListener("click", handleUserInteraction, { once: true });
    window.addEventListener("touchstart", handleUserInteraction, { once: true });
    window.addEventListener("keydown", handleUserInteraction, { once: true });

    return () => {
      window.removeEventListener("click", handleUserInteraction);
      window.removeEventListener("touchstart", handleUserInteraction);
      window.removeEventListener("keydown", handleUserInteraction);
      
      // ØªÙ†Ø¸ÙŠÙ AudioContext Ø¹Ù†Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒÙˆÙ†
      if (audioContextRef.current) {
        audioContextRef.current.close().catch(err => {
          console.error("âŒ Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ø¥ØºÙ„Ø§Ù‚ AudioContext:", err);
        });
      }
    };
  }, []);
  
  // Cancel any in-progress requests
  const cancelRequest = useCallback(() => {
    if (abortControllerRef.current) {
      console.log("ğŸ›‘ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡");
      abortControllerRef.current.abort();
      abortControllerRef.current = null;
      setIsLoading(false);
      setIsAudioLoading(false);
    }
  }, []);
  
  // Ask the AI assistant
  const askAssistant = useCallback(async (question: string): Promise<string | null> => {
    // Cancel any existing request
    cancelRequest();
    
    // Create a new abort controller
    abortControllerRef.current = new AbortController();
    
    try {
      setIsLoading(true);
      
      console.log("ğŸ¤– Ø¥Ø±Ø³Ø§Ù„ Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ:", question);
      
      // Use the AI assistant Supabase Edge Function
      const { data, error } = await supabase.functions.invoke('ai-assistant', {
        body: { userMessage: question }
      });
      
      if (error) {
        console.error("Ø®Ø·Ø£ ÙÙŠ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:", error);
        throw new Error(error.message);
      }
      
      if (!data || !data.response) {
        console.error("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø£ÙŠ Ø±Ø¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ");
        throw new Error("Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ");
      }
      
      console.log("âœ… ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø±Ø¯ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ:", data.response.substring(0, 50) + "...");
      
      return data.response;
    } catch (error) {
      console.error("Ø®Ø·Ø£ ÙÙŠ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:", error);
      
      if (error instanceof Error && error.name === "AbortError") {
        console.log("ğŸ›‘ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ø·Ù„Ø¨");
        return null;
      }
      
      toast({
        title: "Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„",
        description: "Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
        variant: "destructive",
      });
      
      return null;
    } finally {
      setIsLoading(false);
    }
  }, [toast, cancelRequest]);
  
  // Ø·Ø±ÙŠÙ‚Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø¯ÙÙ‚ Ø§Ù„ØµÙˆØª Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† ElevenLabs
  const streamToSpeech = useCallback(async (text: string, callbacks?: TextToSpeechCallbacks): Promise<void> => {
    if (!text.trim()) {
      console.error("âŒ Ø§Ù„Ù†Øµ ÙØ§Ø±ØºØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ ØµÙˆØª");
      return;
    }

    try {
      setIsAudioLoading(true);
      
      // Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø³ØªÙ…Ø¹ ØµÙˆØªÙŠ
      if (!audioContextRef.current) {
        try {
          const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext;
          audioContextRef.current = new AudioContextClass();
          console.log("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ AudioContext Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø¯ÙÙ‚");
        } catch (err) {
          console.error("âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ AudioContext:", err);
          throw new Error("Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙŠØ§Ù‚ ØµÙˆØªÙŠ. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…ØªØµÙØ­ ÙŠØ¯Ø¹Ù… Web Audio API.");
        }
      }

      // Ø¥Ø°Ø§ ÙƒØ§Ù† AudioContext Ù…ØªÙˆÙ‚ÙÙ‹Ø§ØŒ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„Ù‡
      if (audioContextRef.current.state === "suspended") {
        await audioContextRef.current.resume();
        console.log("âœ… ØªÙ… Ø§Ø³ØªØ¦Ù†Ø§Ù Ø¹Ù…Ù„ AudioContext");
      }

      console.log("ğŸ”Š Ø¨Ø¯Ø¡ ØªØ¯ÙÙ‚ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª:", text.substring(0, 50) + "...");
      callbacks?.onStart?.();

      // Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ ÙˆØ¸ÙŠÙØ© Ø¯ÙÙ‚ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…
      const response = await fetch(`${supabase.functions.url}/text-to-speech`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${supabase.auth.session()?.access_token || ''}`,
        },
        body: JSON.stringify({ 
          text, 
          stream: true
        })
      });

      if (!response.ok || !response.body) {
        throw new Error(`ÙØ´Ù„ ÙÙŠ Ø¯ÙÙ‚ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…: ${response.status} ${response.statusText}`);
      }

      console.log("âœ… ØªÙ… Ø¨Ø¯Ø¡ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø¯ÙÙ‚ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù…");

      // Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø±Ø¦ Ø§Ù„Ø¯ÙÙ‚
      const reader = response.body.getReader();
      const streamProcessor = new ReadableStream({
        async start(controller) {
          try {
            // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯ÙÙ‚
            while (true) {
              const { done, value } = await reader.read();
              
              if (done) {
                console.log("âœ… Ø§Ù†ØªÙ‡Ù‰ Ø¯ÙÙ‚ Ø§Ù„ØµÙˆØª");
                controller.close();
                callbacks?.onEnd?.();
                break;
              }
              
              // Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© ØªØ¹Ø§Ù„Ø¬ ÙƒÙ„ Ù‚Ø·Ø¹Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© ÙˆØªØ´ØºÙ„Ù‡Ø§
              await processAudioChunk(value, audioContextRef.current!);
              callbacks?.onChunk?.(value);
              
              // Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¯ÙÙ‚
              controller.enqueue(value);
            }
          } catch (error) {
            console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙÙ‚ Ø§Ù„ØµÙˆØª:", error);
            controller.error(error);
          } finally {
            setIsAudioLoading(false);
          }
        }
      });

      // Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙÙ‚
      const stream = new Response(streamProcessor);
      
      // Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù…Ù† Ø§Ù„Ø¯ÙÙ‚
      async function processAudioChunk(chunk: Uint8Array, audioContext: AudioContext) {
        try {
          // ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ AudioBuffer
          const audioBuffer = await audioContext.decodeAudioData(chunk.buffer);
          
          // Ø¥Ù†Ø´Ø§Ø¡ Ù…ØµØ¯Ø± ØµÙˆØªÙŠ
          const source = audioContext.createBufferSource();
          source.buffer = audioBuffer;
          source.connect(audioContext.destination);
          
          // Ø¥Ø®Ø·Ø§Ø± Ø¨Ø£Ù†Ù†Ø§ Ø¨Ø¯Ø£Ù†Ø§ ØªØ¯ÙÙ‚ Ø§Ù„ØµÙˆØª
          if (callbacks?.onStreamStart) {
            callbacks.onStreamStart(source);
          }
          
          // ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª
          source.start(0);
          
          // Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ Ø§Ù†ØªÙ‡Ø§Ø¡ ØªØ´ØºÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø·Ø¹Ø©
          return new Promise<void>((resolve) => {
            source.onended = () => resolve();
          });
        } catch (error) {
          console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø·Ø¹Ø© Ø§Ù„ØµÙˆØª:", error);
        }
      }

      // Ø§Ø¨Ø¯Ø£ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¯ÙÙ‚
      return await stream.arrayBuffer();
      
    } catch (error) {
      console.error("âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ¯ÙÙ‚ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…:", error);
      setIsAudioLoading(false);
      callbacks?.onEnd?.();
      
      toast({
        title: "Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª",
        description: error instanceof Error ? error.message : "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª",
        variant: "destructive",
      });
    }
  }, [toast, supabase]);
  
  // Convert text to speech (old method for compatibility)
  const textToSpeech = useCallback(async (text: string, callbacks?: TextToSpeechCallbacks): Promise<string | null> => {
    try {
      setIsAudioLoading(true);
      
      // Create a new abort controller
      if (!abortControllerRef.current) {
        abortControllerRef.current = new AbortController();
      }
      
      console.log("ğŸ”Š ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…:", text.substring(0, 50) + "...");
      
      // Call the text-to-speech Edge Function
      const { data, error } = await supabase.functions.invoke('text-to-speech', {
        body: { text, stream: false }
      });
      
      if (error || !data) {
        console.error("Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…:", error || "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª");
        throw new Error(error?.message || "ÙØ´Ù„ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…");
      }
      
      if (!data.audio) {
        console.error("Ù„Ù… ÙŠØªÙ… Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ØµÙˆØªÙŠØ©");
        throw new Error("Ù„Ù… ÙŠØªÙ… Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª ØµÙˆØªÙŠØ©");
      }
      
      console.log("âœ… ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª ØµÙˆØªÙŠØ© Ø¨Ù†Ø¬Ø§Ø­. Ø·ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:", data.audio.length);
      
      // Create audio URL from base64
      const audioUrl = `data:audio/mp3;base64,${data.audio}`;
      console.log("âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… Ø¨Ù†Ø¬Ø§Ø­ ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØª");
      
      // ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ© Ù‚Ø¨Ù„ Ø¥Ø±Ø¬Ø§Ø¹Ù‡Ø§
      if (!isValidBase64(data.audio)) {
        console.error("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³ØªÙ„Ù…Ø© Ù„ÙŠØ³Øª Ø¨ØªÙ†Ø³ÙŠÙ‚ base64 ØµØ§Ù„Ø­");
        throw new Error("Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØª ØºÙŠØ± ØµØ§Ù„Ø­Ø©");
      }
      
      // Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ø³Ø¨Ù‚Ù‹Ø§
      try {
        const preloadAudio = new Audio();
        preloadAudio.src = audioUrl;
        
        // ÙˆØ¶Ø¹ Ù…Ø³ØªÙ…Ø¹ Ù…Ø¤Ù‚Øª Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØµÙˆØª Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ´ØºÙŠÙ„
        await new Promise<void>((resolve, reject) => {
          const timeout = setTimeout(() => {
            reject(new Error("Ø§Ù†ØªÙ‡Øª Ù…Ù‡Ù„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª"));
          }, 3000);
          
          preloadAudio.oncanplaythrough = () => {
            clearTimeout(timeout);
            resolve();
          };
          
          preloadAudio.onerror = (e) => {
            clearTimeout(timeout);
            reject(new Error(`ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª: ${e}`));
          };
          
          // Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø³Ø¨Ù‚
          preloadAudio.load();
        });
        
        // ØªÙ… Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­
        console.log("âœ… ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ù…Ù„Ù Ø§Ù„ØµÙˆØª Ù„Ù„ØªØ´ØºÙŠÙ„");
      } catch (preloadError) {
        console.error("âŒ ÙØ´Ù„ Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØª:", preloadError);
        // Ù†Ø³ØªÙ…Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† Ø§Ù„Ø®Ø·Ø£ØŒ Ù„ÙƒÙ† Ù†Ø³Ø¬Ù„Ù‡
      }
      
      // Callback for start of synthesis
      callbacks?.onStart && callbacks.onStart();
      
      return audioUrl;
    } catch (error) {
      console.error("Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…:", error);
      toast({
        title: "Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª",
        description: "Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ø¯ Ø¥Ù„Ù‰ ØµÙˆØª. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
        variant: "destructive",
      });
      return null;
    } finally {
      setIsAudioLoading(false);
      // The onEnd callback will be handled when the audio actually plays and ends
      // Not here, as we're just returning the URL
    }
  }, [toast]);
  
  // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ØªÙ†Ø³ÙŠÙ‚ base64
  const isValidBase64 = (str: string): boolean => {
    try {
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ù„ÙŠØ³Øª ÙØ§Ø±ØºØ©
      if (!str || str.trim() === '') return false;
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø·ÙˆÙ„ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù€ base64 (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ù…Ø¶Ø§Ø¹Ù 4)
      if (str.length % 4 !== 0) return false;
      
      // Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ø³Ù„Ø³Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø­Ø±Ù base64 ÙÙ‚Ø·
      return /^[A-Za-z0-9+/=]+$/.test(str);
    } catch (e) {
      return false;
    }
  };
  
  return { askAssistant, textToSpeech, streamToSpeech, isLoading, isAudioLoading, cancelRequest };
};
