
import { supabase } from '@/integrations/supabase/client';
import { blobToBase64 } from '@/utils/audioUtils';

/**
 * Service for transcribing speech to text
 */
export const speechTranscriptionService = {
  /**
   * Transcribe audio to text using Supabase Edge Function
   */
  async transcribeAudio(audioBlob: Blob): Promise<string | null> {
    try {
      console.log("ğŸ¤ Ø¨Ø¯Ø¡ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ...", "Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù:", Math.round(audioBlob.size / 1024), "ÙƒÙŠÙ„ÙˆØ¨Ø§ÙŠØª");
      console.log("ğŸ¤ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ:", audioBlob.type);
      
      // Validate audio blob size
      if (audioBlob.size < 1000) {
        console.warn("âš ï¸ Ù…Ù„Ù Ø§Ù„ØµÙˆØª ØµØºÙŠØ± Ø¬Ø¯Ù‹Ø§ØŒ Ù‚Ø¯ Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ø§Ù… Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªÙ…ÙŠÙŠØ²");
        throw new Error("Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù ØµÙˆØª ÙˆØ§Ø¶Ø­. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ ÙˆØ§Ù„ØªØ­Ø¯Ø« Ø¨ØµÙˆØª Ø£Ø¹Ù„Ù‰.");
      }
      
      // Make sure we have MP3 format for compatibility with OpenAI Whisper API
      console.log("ğŸ”„ ØªØ­ÙˆÙŠÙ„ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ mp3...");
      
      // Initialize with the original blob as a fallback
      let processedBlob = audioBlob;
      
      // Force MP3 MIME type to ensure compatibility
      try {
        processedBlob = new Blob([await audioBlob.arrayBuffer()], { type: 'audio/mp3' });
        console.log("âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚:", processedBlob.type);
      } catch (e) {
        console.error("âŒ ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚:", e);
      }
      
      this.logAudioBlobInfo(processedBlob);
      
      // Convert audio to base64
      console.log("ğŸ”„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ ØµÙŠØºØ© Base64...");
      const audioBase64 = await blobToBase64(processedBlob);
      
      if (!audioBase64) {
        throw new Error("ÙØ´Ù„ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ ØµÙŠØºØ© Base64.");
      }
      
      console.log("ğŸ”„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†Øµ...", "Ø·ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:", audioBase64.length);
      
      // Call the Supabase Edge Function
      const { data, error } = await supabase.functions.invoke('voice-to-text', {
        body: { 
          audio: audioBase64,
          language: "ar" // Explicitly set Arabic language
        }
      });

      if (error) {
        console.error('âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ:', error);
        throw new Error(error.message || 'ÙØ´Ù„ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.');
      }

      if (data?.error) {
        console.error('âŒ Ø®Ø·Ø£ Ù…Ù† Ø®Ø¯Ù…Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª:', data.error);
        throw new Error(data.error || 'ÙØ´Ù„ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.');
      }

      if (data && data.text) {
        console.log("âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­:", data.text);
        return data.text.trim();
      } else {
        console.error('âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©', data);
        throw new Error('Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.');
      }
    } catch (err) {
      console.error('âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª:', err);
      throw err;
    }
  },
  
  /**
   * Log debug information about an audio blob
   */
  logAudioBlobInfo(blob: Blob): void {
    console.log(`
      ğŸ” Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù„Ù Ø§Ù„ØµÙˆØª:
      - Ø§Ù„Ø­Ø¬Ù…: ${blob.size} Ø¨Ø§ÙŠØª (${Math.round(blob.size / 1024)} ÙƒÙŠÙ„ÙˆØ¨Ø§ÙŠØª)
      - Ø§Ù„Ù†ÙˆØ¹: ${blob.type}
      - Ø§Ù„ÙˆÙ‚Øª: ${new Date().toISOString()}
    `);
  }
};
