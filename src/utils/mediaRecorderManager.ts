
/**
 * Manager for MediaRecorder operations
 */
export class MediaRecorderManager {
  mediaRecorder: MediaRecorder | null = null;
  stream: MediaStream | null = null;
  audioChunks: Blob[] = [];
  private audioContext: AudioContext | null = null;
  private analyser: AnalyserNode | null = null;
  private dataArray: Uint8Array | null = null;
  
  /**
   * Request microphone access and set up media recorder
   */
  async setupMediaRecorder(): Promise<MediaStream> {
    try {
      console.log("ğŸ¤ Ø·Ù„Ø¨ Ø¥Ø°Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†...");
      
      // Ensure we're requesting mic permission on user interaction
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        }
      });
      
      this.stream = stream;
      console.log("âœ… ØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø°Ù† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†");
      
      // Create audio context for level analysis
      try {
        this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        this.analyser = this.audioContext.createAnalyser();
        this.analyser.fftSize = 256;
        
        const source = this.audioContext.createMediaStreamSource(stream);
        source.connect(this.analyser);
        
        this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
        console.log("âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø­Ù„Ù„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª");
      } catch (err) {
        console.error("âš ï¸ ØªØ¹Ø°Ø± Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø­Ù„Ù„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª:", err);
      }
      
      return stream;
    } catch (err) {
      console.error('âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†:', err);
      throw new Error('Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†');
    }
  }
  
  /**
   * Create and configure the media recorder
   */
  createMediaRecorder(
    onStart: () => void,
    onDataAvailable: (data: Blob) => void,
    onStop: () => void,
    onError: (event: Event) => void
  ): MediaRecorder | null {
    if (!this.stream) {
      console.error("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ¯ÙÙ‚ ØµÙˆØªÙŠ Ù…ØªØ§Ø­");
      return null;
    }
    
    // Use appropriate audio format with good compatibility
    const options = {
      mimeType: this.getSupportedMimeType(),
      audioBitsPerSecond: 128000
    };
    
    console.log("ğŸ¤ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³Ø¬Ù„ Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…:", options.mimeType);
    
    try {
      const mediaRecorder = new MediaRecorder(this.stream, options);
      
      mediaRecorder.onstart = onStart;
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data && event.data.size > 0) {
          this.audioChunks.push(event.data);
          onDataAvailable(event.data);
          console.log(`ğŸ”Š ØªÙ… Ø§Ù„ØªÙ‚Ø§Ø· Ø´Ø±ÙŠØ­Ø© ØµÙˆØªÙŠØ© Ø¨Ø­Ø¬Ù…: ${event.data.size} Ø¨Ø§ÙŠØª`);
        }
      };
      
      mediaRecorder.onstop = onStop;
      mediaRecorder.onerror = onError;
      
      this.mediaRecorder = mediaRecorder;
      return mediaRecorder;
    } catch (err) {
      console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³Ø¬Ù„ Ø§Ù„ØµÙˆØª:", err);
      return null;
    }
  }

  /**
   * Find a supported MIME type for audio recording
   */
  private getSupportedMimeType(): string {
    const types = [
      'audio/webm',
      'audio/webm;codecs=opus',
      'audio/ogg;codecs=opus',
      'audio/mp4',
      'audio/mpeg',
      ''  // Empty string is the browser default
    ];
    
    for (const type of types) {
      if (!type || MediaRecorder.isTypeSupported(type)) {
        return type;
      }
    }
    
    return '';  // Use browser default
  }
  
  /**
   * Get collected audio chunks as a blob
   */
  getAudioBlob(): Blob | null {
    if (this.audioChunks.length === 0) return null;
    
    const mimeType = this.getSupportedMimeType() || 'audio/webm';
    return new Blob(this.audioChunks, { type: mimeType });
  }
  
  /**
   * Start recording
   */
  startRecording() {
    this.audioChunks = [];
    
    if (this.mediaRecorder) {
      try {
        // Try setting a smaller timeslice for more frequent ondataavailable events
        this.mediaRecorder.start(500); // Get data every 500ms for more responsive waveform
        console.log("ğŸ™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ");
      } catch (err) {
        console.error("âŒ Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„:", err);
      }
    } else {
      console.error("âŒ Ù„Ù… ÙŠØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø³Ø¬Ù„ Ø§Ù„ØµÙˆØª");
    }
  }
  
  /**
   * Stop recording
   */
  stopRecording() {
    if (this.mediaRecorder?.state !== 'inactive') {
      try {
        this.mediaRecorder?.stop();
        console.log("ğŸ›‘ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ");
      } catch (err) {
        console.error("âŒ Ø®Ø·Ø£ Ø¹Ù†Ø¯ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„:", err);
      }
    }
  }

  /**
   * Get current audio level (0-1)
   */
  getCurrentAudioLevel(): number {
    if (!this.analyser || !this.dataArray) return 0;
    
    try {
      this.analyser.getByteFrequencyData(this.dataArray);
      
      // Calculate average volume level
      let sum = 0;
      const length = this.dataArray.length;
      
      // Log the first few values to debug
      if (Math.random() < 0.05) { // Only log occasionally to avoid console spam
        console.log("ğŸ”ˆ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„ØµÙˆØª (Ø¹ÙŠÙ†Ø©):", 
          Array.from(this.dataArray).slice(0, 5).join(", "));
      }
      
      for (let i = 0; i < length; i++) {
        sum += this.dataArray[i];
      }
      const average = sum / length;
      
      // Normalize to 0-1 range
      const level = Math.min(1, average / 128);
      
      // Log audio level occasionally
      if (Math.random() < 0.1 && level > 0.05) {
        console.log(`ğŸ¤ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª Ø§Ù„Ø­Ø§Ù„ÙŠ: ${level.toFixed(2)}`);
      }
      
      return level;
    } catch (err) {
      console.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª:", err);
      return 0;
    }
  }
  
  /**
   * Clean up resources
   */
  cleanup() {
    try {
      if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
        this.mediaRecorder.stop();
      }
      this.mediaRecorder = null;
    } catch (e) {
      console.error('Error stopping media recorder:', e);
    }
    
    try {
      if (this.stream) {
        this.stream.getTracks().forEach(track => track.stop());
        this.stream = null;
      }
    } catch (e) {
      console.error('Error stopping media tracks:', e);
    }
    
    try {
      if (this.audioContext) {
        this.audioContext.close();
        this.audioContext = null;
        this.analyser = null;
      }
    } catch (e) {
      console.error('Error closing audio context:', e);
    }
    
    this.audioChunks = [];
  }
}
